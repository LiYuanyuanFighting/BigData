**Comparison between Decision Tree and Logistic Regression**  
    Both algorithms are really fast. There isn't much to distinguish them in terms of run-time.  
    Logistic regression will work better if there's a single decision boundary, not necessarily parallel to the axis.  
    Decision trees can be applied to situations where there's not just one underlying decision boundary, but many,   
    and will work best if the class labels roughly lie in hyper-rectangular regions.
    Logistic regression is intrinsically simple, it has low variance and so is less prone to over-fitting. Decision  
    trees can be scaled up to be very complex, are are more liable to over-fit. Pruning is applied to avoid this.  
    
